# Big Data with PySpark

# Progress

## Introducation to PySpark

### Getting to know PySpark

 - [x]	What is Spark, anyway?
 - [x]	Using Spark in Python
 - [x]	Examining The SparkContext
 - [x]	Using DataFrames
 - [x]	Creating a SparkSession
 - [x]	Viewing tables
 - [x]	Are you query-ious?
 - [x]	Pandafy a Spark DataFrame
 - [x]	Put some Spark in your data
 - [x]	Dropping the middle man
 
 ### Manipulating data
 - [x]	Creating columns
 - [x]	SQL in a nutshell
 - [x]	SQL in a nutshell (2)
 - [x]	Filtering Data
 - [x]	Selecting
 - [x]	Selecting II
 - [x]	Aggregating
 - [x]	Aggregating II
 - [x]	Grouping and Aggregating I
 - [x]	Grouping and Aggregating II
 - [x]	Joining
 - [x]	Joining II

### Getting started with machine learning pipelines
- [ ]	Machine Learning Pipelines
- [ ]	Join the DataFrames
- [ ]	Data types
- [ ]	String to integer
- [ ]	Create a new column
- [ ]	Making a Boolean
- [ ]	Strings and factors
- [ ]	Carrier
- [ ]	Destination
- [ ]	Assemble a vector
- [ ]	Create the pipeline
- [ ]	Test vs Train
- [ ]	Transform the data
- [ ]	Split the data

### Model tuning and selection

- [ ]	What is logistic regression?
- [ ]	Create the modeler
- [ ]	Cross validation
- [ ]	Create the evaluator
- [ ]	Make a grid
- [ ]	Make the validator
- [ ]	Fit the model(s)
- [ ]	Evaluating binary classifiers
- [ ]	Evaluate the model
